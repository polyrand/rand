{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language identification with fastText\n",
    "  \n",
    "Date: 2019-08-21  \n",
    "Author: Ricardo  \n",
    "Categories: nlp, fasttext, language  \n",
    "Tags: fasttext, nlp, text, language, identification, classification  \n",
    "<!--eofm-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with a multilingual dataset doing language identification is a very important part of the analysis process, here I'll show a way to do a fast ⚡️ and reliable ✨ languague identification with [fasttext](https://fasttext.cc).\n",
    "<!--more-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL;DR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "lid_model = fasttext.load_model('lid.176.bin')\n",
    "\n",
    "def detector(text):\n",
    "    # return empty string if there is no tweet\n",
    "    if text.isspace():\n",
    "        return \"\"\n",
    "    else:\n",
    "        # get first item of the prediction tuple, then split by \"__label__\" and return only language code\n",
    "        return lid_model.predict(text)[0][0].split(\"__label__\")[1]\n",
    "    \n",
    "df['language'] = df['Tweet'].apply(detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to download a dataset to play with. We'll use the [kaggle CLI tool](https://github.com/Kaggle/kaggle-api). Run the following command after installing it or download the dataset [directly from kaggle](https://www.kaggle.com/rtatman/the-umass-global-english-on-twitter-dataset).\n",
    "\n",
    "```bash\n",
    "kaggle datasets download -d rtatman/the-umass-global-english-on-twitter-dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Definitely English</th>\n",
       "      <th>Ambiguous</th>\n",
       "      <th>Definitely Not English</th>\n",
       "      <th>Code-Switched</th>\n",
       "      <th>Ambiguous due to Named Entities</th>\n",
       "      <th>Automatically Generated Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434215992731136000</td>\n",
       "      <td>TR</td>\n",
       "      <td>2014-02-14</td>\n",
       "      <td>Bugün bulusmami lazimdiii</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285903159434563584</td>\n",
       "      <td>TR</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Volkan konak adami tribe sokar yemin ederim :D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285948076496142336</td>\n",
       "      <td>NL</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285965965118824448</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>I felt my first flash of violence at some fool...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286057979831275520</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Ladies drink and get in free till 10:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweet ID Country        Date  \\\n",
       "0  434215992731136000      TR  2014-02-14   \n",
       "1  285903159434563584      TR  2013-01-01   \n",
       "2  285948076496142336      NL  2013-01-01   \n",
       "3  285965965118824448      US  2013-01-01   \n",
       "4  286057979831275520      US  2013-01-01   \n",
       "\n",
       "                                               Tweet  Definitely English  \\\n",
       "0                          Bugün bulusmami lazimdiii                   0   \n",
       "1     Volkan konak adami tribe sokar yemin ederim :D                   0   \n",
       "2                                                Bed                   1   \n",
       "3  I felt my first flash of violence at some fool...                   1   \n",
       "4            Ladies drink and get in free till 10:30                   1   \n",
       "\n",
       "   Ambiguous  Definitely Not English  Code-Switched  \\\n",
       "0          0                       1              0   \n",
       "1          0                       1              0   \n",
       "2          0                       0              0   \n",
       "3          0                       0              0   \n",
       "4          0                       0              0   \n",
       "\n",
       "   Ambiguous due to Named Entities  Automatically Generated Tweets  \n",
       "0                                0                               0  \n",
       "1                                0                               0  \n",
       "2                                0                               0  \n",
       "3                                0                               0  \n",
       "4                                0                               0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('the-umass-global-english-on-twitter-dataset.zip', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are: 10502 tweets.\n",
      "    \n",
      "First 10 tweets:\n",
      "    \n",
      "0                            Bugün bulusmami lazimdiii\n",
      "1       Volkan konak adami tribe sokar yemin ederim :D\n",
      "2                                                  Bed\n",
      "3    I felt my first flash of violence at some fool...\n",
      "4              Ladies drink and get in free till 10:30\n",
      "5                     @Melanynijholtxo ahhahahahah dm!\n",
      "6                                                 Fuck\n",
      "7    Watching #Miranda On bbc1!!! @mermhart u r HIL...\n",
      "8                                       @StizZsti fino\n",
      "9            Shopping! (@ Kohl's) http://t.co/I8ZkQHT9\n",
      "Name: Tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"There are: {df.Tweet.shape[0]} tweets.\n",
    "    \n",
    "First 10 tweets:\n",
    "    \n",
    "{df['Tweet'].head(10)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first 10 tweets we can already see the are multiple languags been used. Lets now use fasttext to classify them. You need to download the language indentification model to use it, run the following shell command if you need to do so.\n",
    "\n",
    "```bash\n",
    "wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use a slightly less accurate but a lot smaller model:\n",
    "\n",
    "```bash\n",
    "wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "lid_model = fasttext.load_model('lid.176.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list in which each item is a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['Tweet'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the language of the first tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      " \t Bugün bulusmami lazimdiii \n",
      " \n",
      " Prediction:\n",
      " \t (('__label__tr',), array([0.77383512]))\n"
     ]
    }
   ],
   "source": [
    "tweet = corpus[0]\n",
    "prediction = lid_model.predict(corpus[0])\n",
    "print(f\"Text:\\n \\t {tweet} \\n \\n Prediction:\\n \\t {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the prediction is a tuple of language label and prediction confidence. Language label is a string with “\\__label__” followed by ISO 639 code of the language. You can check the language codes [here](https://www.loc.gov/standards/iso639-2/php/code_list.php) and the languages supported by fasttext at the end of [their blog post](https://fasttext.cc/blog/2017/10/02/blog-post.html).\n",
    "\n",
    "Lets try with a different one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      " \t Ladies drink and get in free till 10:30 \n",
      " \n",
      " Prediction:\n",
      " \t (('__label__en',), array([0.65553886]))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text:\\n \\t {corpus[4]} \\n \\n Prediction:\\n \\t {lid_model.predict(corpus[4])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new column with the langue of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector(text):\n",
    "    # return empty string if there is no tweet\n",
    "    if text.isspace():\n",
    "        return \"\"\n",
    "    else:\n",
    "        # get first item of the prediction tuple, then split by \"__label__\" and return only language code\n",
    "        return lid_model.predict(text)[0][0].split(\"__label__\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 258 ms, sys: 4.17 ms, total: 262 ms\n",
      "Wall time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['language'] = df['Tweet'].apply(detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added the `%%time` IPython [command](https://ipython.readthedocs.io/en/stable/interactive/magics.html) to show one of the main reasons to use fasttext, the speed ⚡️. **In 250ms I processed 10502 tweets** working on a 2016 laptop with a dual-core 2 GHz Intel Core i5 processor.\n",
    "\n",
    "The speed of fastText can also be compared with [langid.py](https://github.com/saffsd/langid.py) in this table from their [blog](https://fasttext.cc/blog/2017/10/02/blog-post.html).\n",
    "\n",
    "![](https://fasttext.cc/img/blog/2017-10-02-blog-post-img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if we wanted to work only with a subset of the languages and convert the rest to _\"unk\"_ (and maybe use a multilingual model when working with them), we can use the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the 4 top languages according to the current predictions\n",
    "languanges_keep = df.language.value_counts().index[:4].to_list()\n",
    "\n",
    "# create a custom list\n",
    "languanges_keep = [\"en\", \"es\", \"pt\", \"ja\"]\n",
    "\n",
    "df.loc[df.language.apply(lambda x: x not in languanges_keep), 'language'] = \"unk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en     5735\n",
       "unk    2247\n",
       "es     1139\n",
       "pt      876\n",
       "ja      505\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from here we can keep working with our text data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
